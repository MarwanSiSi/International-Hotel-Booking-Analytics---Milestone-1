{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12711806,"sourceType":"datasetVersion","datasetId":8034264}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":94.44737,"end_time":"2025-10-15T21:19:25.661857","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-15T21:17:51.214487","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport missingno as msno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import Sequential, Input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom sklearn.preprocessing import LabelEncoder\ntf.keras.backend.clear_session()\nimport shap\nimport lime\nimport lime.lime_tabular","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-10-23T20:06:45.090113Z","iopub.execute_input":"2025-10-23T20:06:45.090355Z","iopub.status.idle":"2025-10-23T20:07:14.399016Z","shell.execute_reply.started":"2025-10-23T20:06:45.090328Z","shell.execute_reply":"2025-10-23T20:07:14.398233Z"},"papermill":{"duration":23.004731,"end_time":"2025-10-15T21:18:19.365496","exception":false,"start_time":"2025-10-15T21:17:56.360765","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:07:14.399696Z","iopub.execute_input":"2025-10-23T20:07:14.400191Z","iopub.status.idle":"2025-10-23T20:07:14.558408Z","shell.execute_reply.started":"2025-10-23T20:07:14.400171Z","shell.execute_reply":"2025-10-23T20:07:14.557497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_hotels = pd.read_csv('/kaggle/input/hotels.csv')\ndf_reviews = pd.read_csv('/kaggle/input/reviews.csv')\ndf_users = pd.read_csv('/kaggle/input/users.csv')\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:14.560628Z","iopub.execute_input":"2025-10-23T20:07:14.560896Z","iopub.status.idle":"2025-10-23T20:07:14.809436Z","shell.execute_reply.started":"2025-10-23T20:07:14.560875Z","shell.execute_reply":"2025-10-23T20:07:14.808563Z"},"papermill":{"duration":0.38668,"end_time":"2025-10-15T21:18:19.758176","exception":false,"start_time":"2025-10-15T21:18:19.371496","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_hotels.head()","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:14.810413Z","iopub.execute_input":"2025-10-23T20:07:14.810763Z","iopub.status.idle":"2025-10-23T20:07:14.846710Z","shell.execute_reply.started":"2025-10-23T20:07:14.810732Z","shell.execute_reply":"2025-10-23T20:07:14.845995Z"},"papermill":{"duration":0.040148,"end_time":"2025-10-15T21:18:19.804049","exception":false,"start_time":"2025-10-15T21:18:19.763901","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_hotels = df_hotels.drop(['star_rating','lat','lon'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:07:14.847494Z","iopub.execute_input":"2025-10-23T20:07:14.847807Z","iopub.status.idle":"2025-10-23T20:07:14.862487Z","shell.execute_reply.started":"2025-10-23T20:07:14.847780Z","shell.execute_reply":"2025-10-23T20:07:14.861562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_hotels.info()","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:14.863473Z","iopub.execute_input":"2025-10-23T20:07:14.863857Z","iopub.status.idle":"2025-10-23T20:07:14.896205Z","shell.execute_reply.started":"2025-10-23T20:07:14.863825Z","shell.execute_reply":"2025-10-23T20:07:14.895408Z"},"papermill":{"duration":0.034728,"end_time":"2025-10-15T21:18:19.845047","exception":false,"start_time":"2025-10-15T21:18:19.810319","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"msno.matrix(df_hotels) # if there is white -> null values","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:14.897161Z","iopub.execute_input":"2025-10-23T20:07:14.897539Z","iopub.status.idle":"2025-10-23T20:07:15.638885Z","shell.execute_reply.started":"2025-10-23T20:07:14.897517Z","shell.execute_reply":"2025-10-23T20:07:15.637982Z"},"papermill":{"duration":0.735979,"end_time":"2025-10-15T21:18:20.587145","exception":false,"start_time":"2025-10-15T21:18:19.851166","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_hotels.duplicated().sum() # shows which cols have duplicates\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:15.639874Z","iopub.execute_input":"2025-10-23T20:07:15.640266Z","iopub.status.idle":"2025-10-23T20:07:15.647774Z","shell.execute_reply.started":"2025-10-23T20:07:15.640243Z","shell.execute_reply":"2025-10-23T20:07:15.646790Z"},"papermill":{"duration":0.017689,"end_time":"2025-10-15T21:18:20.612310","exception":false,"start_time":"2025-10-15T21:18:20.594621","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:15.651841Z","iopub.execute_input":"2025-10-23T20:07:15.652082Z","iopub.status.idle":"2025-10-23T20:07:15.683344Z","shell.execute_reply.started":"2025-10-23T20:07:15.652065Z","shell.execute_reply":"2025-10-23T20:07:15.682417Z"},"papermill":{"duration":0.025649,"end_time":"2025-10-15T21:18:20.645823","exception":false,"start_time":"2025-10-15T21:18:20.620174","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_reviews.info()","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:15.684557Z","iopub.execute_input":"2025-10-23T20:07:15.684771Z","iopub.status.idle":"2025-10-23T20:07:15.714595Z","shell.execute_reply.started":"2025-10-23T20:07:15.684754Z","shell.execute_reply":"2025-10-23T20:07:15.713871Z"},"papermill":{"duration":0.030045,"end_time":"2025-10-15T21:18:20.683334","exception":false,"start_time":"2025-10-15T21:18:20.653289","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"msno.matrix(df_reviews) #if there is white -> null values","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:15.715456Z","iopub.execute_input":"2025-10-23T20:07:15.715743Z","iopub.status.idle":"2025-10-23T20:07:16.414640Z","shell.execute_reply.started":"2025-10-23T20:07:15.715713Z","shell.execute_reply":"2025-10-23T20:07:16.413622Z"},"papermill":{"duration":0.75388,"end_time":"2025-10-15T21:18:21.444856","exception":false,"start_time":"2025-10-15T21:18:20.690976","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_reviews.duplicated().sum() # shows which cols have duplicates\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:16.415737Z","iopub.execute_input":"2025-10-23T20:07:16.416066Z","iopub.status.idle":"2025-10-23T20:07:16.458982Z","shell.execute_reply.started":"2025-10-23T20:07:16.416045Z","shell.execute_reply":"2025-10-23T20:07:16.458170Z"},"papermill":{"duration":0.05687,"end_time":"2025-10-15T21:18:21.510564","exception":false,"start_time":"2025-10-15T21:18:21.453694","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_users.head(10)","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:16.459824Z","iopub.execute_input":"2025-10-23T20:07:16.460136Z","iopub.status.idle":"2025-10-23T20:07:16.470387Z","shell.execute_reply.started":"2025-10-23T20:07:16.460112Z","shell.execute_reply":"2025-10-23T20:07:16.469410Z"},"papermill":{"duration":0.023177,"end_time":"2025-10-15T21:18:21.542627","exception":false,"start_time":"2025-10-15T21:18:21.519450","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_users.info()","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:16.471397Z","iopub.execute_input":"2025-10-23T20:07:16.471704Z","iopub.status.idle":"2025-10-23T20:07:16.496651Z","shell.execute_reply.started":"2025-10-23T20:07:16.471676Z","shell.execute_reply":"2025-10-23T20:07:16.495622Z"},"papermill":{"duration":0.023343,"end_time":"2025-10-15T21:18:21.574840","exception":false,"start_time":"2025-10-15T21:18:21.551497","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"msno.matrix(df_users) #if there is white -> null values","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:16.497661Z","iopub.execute_input":"2025-10-23T20:07:16.497992Z","iopub.status.idle":"2025-10-23T20:07:16.963797Z","shell.execute_reply.started":"2025-10-23T20:07:16.497965Z","shell.execute_reply":"2025-10-23T20:07:16.962861Z"},"papermill":{"duration":0.480251,"end_time":"2025-10-15T21:18:22.064025","exception":false,"start_time":"2025-10-15T21:18:21.583774","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_users.duplicated().sum() # shows which cols have duplicates\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:16.964999Z","iopub.execute_input":"2025-10-23T20:07:16.965342Z","iopub.status.idle":"2025-10-23T20:07:16.973396Z","shell.execute_reply.started":"2025-10-23T20:07:16.965314Z","shell.execute_reply":"2025-10-23T20:07:16.972741Z"},"papermill":{"duration":0.021358,"end_time":"2025-10-15T21:18:22.095511","exception":false,"start_time":"2025-10-15T21:18:22.074153","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Data Engineering Questions","metadata":{}},{"cell_type":"markdown","source":"**1. Merge all dfs**","metadata":{}},{"cell_type":"code","source":"# Merge all dataframes\ndf_merged = df_reviews.merge(df_users, on='user_id', how='left') \\\n                      .merge(df_hotels, on='hotel_id', how='left')\n\ndf_merged.info()\n\ndf_merged[['country_x', 'country_y', 'hotel_name','user_id']]\n\npd.set_option('display.max_columns', None)\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:16.974338Z","iopub.execute_input":"2025-10-23T20:07:16.974626Z","iopub.status.idle":"2025-10-23T20:07:17.066327Z","shell.execute_reply.started":"2025-10-23T20:07:16.974596Z","shell.execute_reply":"2025-10-23T20:07:17.065445Z"},"papermill":{"duration":0.117904,"end_time":"2025-10-15T21:18:22.223314","exception":false,"start_time":"2025-10-15T21:18:22.105410","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**2. Check correlations between features**","metadata":{}},{"cell_type":"code","source":"corr = df_merged.corr(numeric_only=True)\n\n# Plot the correlation heatmap\nplt.figure(figsize=(12, 8))\nsns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title(\"Correlation Heatmap of All Numeric Features\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:07:17.067127Z","iopub.execute_input":"2025-10-23T20:07:17.067384Z","iopub.status.idle":"2025-10-23T20:07:17.909192Z","shell.execute_reply.started":"2025-10-23T20:07:17.067366Z","shell.execute_reply":"2025-10-23T20:07:17.908301Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**3. In this step, we analyze which city received the highest average overall score for each traveller type.**","metadata":{}},{"cell_type":"code","source":"# Group by traveller type and city to compute average overall score\ncity_scores = (\n    df_merged.groupby(['traveller_type', 'city'])['score_overall']\n    .mean()\n    .reset_index() # it converts the index levels back into normal columns of the DataFrame.\n)\n\n\n\n# Find the best city for each traveller type\nbest_city_per_type = city_scores.loc[\n    city_scores.groupby('traveller_type')['score_overall'].idxmax() \n    # idxmax-> finds the index (row label) of the maximum value within each group.\n]\n\nprint(best_city_per_type)","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:17.910371Z","iopub.execute_input":"2025-10-23T20:07:17.910685Z","iopub.status.idle":"2025-10-23T20:07:17.933604Z","shell.execute_reply.started":"2025-10-23T20:07:17.910661Z","shell.execute_reply":"2025-10-23T20:07:17.932778Z"},"papermill":{"duration":0.035691,"end_time":"2025-10-15T21:18:22.269230","exception":false,"start_time":"2025-10-15T21:18:22.233539","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**4. This block creates bar charts to visualize how each traveller type rated different cities, highlighting the top-rated city for each group.**","metadata":{}},{"cell_type":"code","source":"for ttype in sorted(city_scores['traveller_type'].dropna().unique()):\n    df_t = city_scores[city_scores['traveller_type'] == ttype]\n\n    # Find index of the city with the highest score\n    max_idx = df_t['score_overall'].idxmax()\n\n    plt.figure(figsize=(12,6))\n    bars = plt.bar(\n        df_t['city'],\n        df_t['score_overall'],\n        color=['orange' if i == max_idx else 'skyblue' for i in df_t.index]\n    )\n\n    # Add value labels with extra space above bars\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(\n            bar.get_x() + bar.get_width()/2,\n            height + 0.15,         # ⬅️ Increased from 0.05 to 0.15 for more space\n            f\"{height:.2f}\",\n            ha='center', va='bottom',\n            rotation=90, fontsize=9\n        )\n\n    # Titles and axes\n    plt.title(f'Average Overall Score per City — {ttype}', fontsize=14)\n    plt.xlabel('City')\n    plt.ylabel('Average Overall Score')\n    plt.xticks(rotation=45, ha='right')\n\n    # Add top margin to prevent clipping of numbers\n    plt.ylim(0, df_t['score_overall'].max() + 1)\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:17.934596Z","iopub.execute_input":"2025-10-23T20:07:17.935391Z","iopub.status.idle":"2025-10-23T20:07:19.336163Z","shell.execute_reply.started":"2025-10-23T20:07:17.935369Z","shell.execute_reply":"2025-10-23T20:07:19.335320Z"},"papermill":{"duration":1.532478,"end_time":"2025-10-15T21:18:23.811918","exception":false,"start_time":"2025-10-15T21:18:22.279440","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**5. This section identifies which countries each age group rated highest in terms of value for money.**","metadata":{}},{"cell_type":"code","source":"value_for_money_scores = (\n    df_merged\n    .groupby(['age_group', 'country_y'])['score_value_for_money']\n    .mean()\n    .reset_index()\n)\n\n\n\n# For each age_group, pick top 3 countries\ntop3_value_per_age = (\n    value_for_money_scores\n    .sort_values(['age_group', 'score_value_for_money'], ascending=[True, False])\n    .groupby('age_group')\n    .head(3)\n)\n\ntop3_value_per_age\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:19.337129Z","iopub.execute_input":"2025-10-23T20:07:19.337444Z","iopub.status.idle":"2025-10-23T20:07:19.360744Z","shell.execute_reply.started":"2025-10-23T20:07:19.337412Z","shell.execute_reply":"2025-10-23T20:07:19.359779Z"},"papermill":{"duration":0.042824,"end_time":"2025-10-15T21:18:23.872306","exception":false,"start_time":"2025-10-15T21:18:23.829482","status":"completed"},"tags":[],"trusted":true,"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**6. This section visualizes the top three countries that received the highest “value-for-money” scores for each age group.**","metadata":{}},{"cell_type":"code","source":"# --- Step 1: prepare and rank your data ---\ndf = (\n    top3_value_per_age\n    .sort_values(['age_group', 'score_value_for_money'], ascending=[True, False])\n    .copy()\n)\ndf['rank'] = df.groupby('age_group').cumcount() + 1\n\nage_groups = list(df['age_group'].dropna().unique())\nage_groups.sort()\n\n# --- Step 2: helper to collect heights and names for each rank ---\ndef values_for_rank(r):\n    vals, names = [], []\n    for age in age_groups:\n        row = df[(df['age_group'] == age) & (df['rank'] == r)]\n        if not row.empty:\n            vals.append(float(row['score_value_for_money'].iloc[0]))\n            names.append(str(row['country_y'].iloc[0]))\n        else:\n            vals.append(np.nan)\n            names.append(\"\")\n    return np.array(vals), np.array(names)\n\ny1, c1 = values_for_rank(1)\ny2, c2 = values_for_rank(2)\ny3, c3 = values_for_rank(3)\n\n# --- Step 3: bar positions and layout ---\nn_groups = len(age_groups)\nx = np.arange(n_groups)\nbar_w = 0.22\noffsets = [-bar_w, 0, bar_w]\n\nplt.figure(figsize=(14, 6))\n\n# --- Step 4: draw bars ---\nb1 = plt.bar(x + offsets[0], y1, width=bar_w,color='gold', label='Rank 1 (best)')\nb2 = plt.bar(x + offsets[1], y2, width=bar_w,color='silver', label='Rank 2')\nb3 = plt.bar(x + offsets[2], y3, width=bar_w,color='brown', label='Rank 3')\n\n# --- Step 5: add country + score labels above bars (with more space) ---\ndef label_bars(bars, names):\n    for bar, name in zip(bars, names):\n        h = bar.get_height()\n        if np.isnan(h):\n            continue\n        plt.text(\n            bar.get_x() + bar.get_width()/2,\n            h + 0.001,                # ⬅️ more vertical space above each label\n            f\"{name}\\n{h:.2f}\",\n            ha='center', va='bottom',\n            rotation=45, fontsize=9\n        )\n\nlabel_bars(b1, c1)\nlabel_bars(b2, c2)\nlabel_bars(b3, c3)\n\n# --- Step 6: labels, legend, and axis styling ---\nplt.xticks(x, age_groups, rotation=0)\nplt.xlabel('Age Group')\nplt.ylabel('Average Value-for-Money Score')\nplt.title('Top 3 Countries by Value-for-Money per Age Group')\n\n# move legend farther away to avoid overlap\nplt.legend(\n    loc='upper left',\n    bbox_to_anchor=(1.02, 1.0),\n    borderaxespad=0,\n    frameon=False\n)\n\n# --- Step 7: extra headroom for labels ---\ntop_y = np.nanmax([y1.max(), y2.max(), y3.max()])\nplt.ylim(0, top_y + 1.5)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:19.362028Z","iopub.execute_input":"2025-10-23T20:07:19.362350Z","iopub.status.idle":"2025-10-23T20:07:19.669673Z","shell.execute_reply.started":"2025-10-23T20:07:19.362324Z","shell.execute_reply":"2025-10-23T20:07:19.668855Z"},"papermill":{"duration":0.337266,"end_time":"2025-10-15T21:18:24.226299","exception":false,"start_time":"2025-10-15T21:18:23.889033","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"markdown","source":"**This block prepares data to predict the hotel’s region (country_group) using review scores + user attributes.**","metadata":{}},{"cell_type":"code","source":"# --- Step 1: Map countries to groups ---\ncountry_to_group = {\n    'United States': 'North_America',\n    'Canada': 'North_America',\n    'Germany': 'Western_Europe',\n    'France': 'Western_Europe',\n    'United Kingdom': 'Western_Europe',\n    'Netherlands': 'Western_Europe',\n    'Spain': 'Western_Europe',\n    'Italy': 'Western_Europe',\n    'Russia': 'Eastern_Europe',\n    'China': 'East_Asia',\n    'Japan': 'East_Asia',\n    'South Korea': 'East_Asia',\n    'Thailand': 'Southeast_Asia',\n    'Singapore': 'Southeast_Asia',\n    'United Arab Emirates': 'Middle_East',\n    'Turkey': 'Middle_East',\n    'Egypt': 'Africa',\n    'Nigeria': 'Africa',\n    'South Africa': 'Africa',\n    'Australia': 'Oceania',\n    'New Zealand': 'Oceania',\n    'Brazil': 'South_America',\n    'Argentina': 'South_America',\n    'India': 'South_Asia',\n    'Mexico': 'North_America_Mexico'\n}\n\n# --- Step 2: Add `country_group` to hotels data ---\ndf_hotels['country_group'] = df_hotels['country'].map(country_to_group)\n\n# --- Step 3: Merge all dataframes ---\ndf_merged_new = (\n    df_reviews\n      .merge(df_users,  on='user_id',  how='left', suffixes=('', '_user'))\n      .merge(df_hotels, on='hotel_id', how='left', suffixes=('', '_hotel'))\n)\n\n# --- Step 4: Define target ---\ny = df_merged_new['country_group']\n\n# --- Step 5: Define features (exclude country, country_group, hotel_id, user_id) ---\ncategorical_cols = ['user_gender', 'age_group', 'traveller_type']\nnumeric_cols = [\n    'score_overall', 'score_cleanliness', 'score_comfort',\n    'score_facilities', 'score_location', 'score_staff', 'score_value_for_money'\n]\n\n# Drop rows with missing target (if any)\ndf_merged_new = df_merged_new.dropna(subset=['country_group'])\n\n# --- Step 6: One-hot encode categorical features ---\nohe_model = OneHotEncoder(\n    drop='first',\n    sparse_output=False,\n    handle_unknown='ignore'\n)\nX_ohe = ohe_model.fit_transform(df_merged_new[categorical_cols])\nohe_feature_names = ohe_model.get_feature_names_out(categorical_cols)\n\n\nscaler = StandardScaler()\n\n# --- Encode target labels ---\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\n#FOR MODEL 2 (WITH COMFORT_BASE)\n#########################################################\n# --- Step 1: Create a new numeric feature list including comfort_base ---\nnumeric_cols_with_base = [\n    'comfort_base', \n    'score_overall', 'score_cleanliness', 'score_comfort',\n    'score_facilities', 'score_location', 'score_staff', 'score_value_for_money'\n]\n\n# --- Step 2: Recreate the scaled + encoded features just for model2 ---\nX_scaled_with_base = scaler.fit_transform(df_merged_new[numeric_cols_with_base])\nX_all_with_base = np.hstack([X_scaled_with_base, X_ohe])  # reuse same OHE\n\n# --- Step 3: Split data (different variable names so it doesn’t overwrite) ---\nfrom sklearn.model_selection import train_test_split\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(\n    X_all_with_base, y_encoded,\n    test_size=0.2, random_state=42, stratify=y_encoded\n)\n\ny_train2 = y_train2.astype(np.int32).flatten()\ny_test2 = y_test2.astype(np.int32).flatten()\n##########################################################################\n\n# --- Step 7: Scale numerical features ---\nX_scaled = scaler.fit_transform(df_merged_new[numeric_cols])\n\n# --- Step 8: Combine all features ---\nX_all = np.hstack([X_scaled, X_ohe])\n\n# Create a mapping of encoded values → original labels\nlabel_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n\n# Optionally make a reverse mapping too\n# reverse_mapping = dict(zip(y_encoded, y))\n\nprint(y_encoded)\n\nprint(\"Label Mapping:\")\nfor k, v in label_mapping.items():\n    print(f\"{k} → {v}\")\n\ny.head()","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:19.670723Z","iopub.execute_input":"2025-10-23T20:07:19.671059Z","iopub.status.idle":"2025-10-23T20:07:19.895844Z","shell.execute_reply.started":"2025-10-23T20:07:19.671031Z","shell.execute_reply":"2025-10-23T20:07:19.894962Z"},"papermill":{"duration":0.283166,"end_time":"2025-10-15T21:18:24.527996","exception":false,"start_time":"2025-10-15T21:18:24.244830","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_ohe)\nprint(ohe_feature_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:09:52.680979Z","iopub.execute_input":"2025-10-23T21:09:52.681287Z","iopub.status.idle":"2025-10-23T21:09:52.687363Z","shell.execute_reply.started":"2025-10-23T21:09:52.681266Z","shell.execute_reply":"2025-10-23T21:09:52.686317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged_new['country_group'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:07:19.896851Z","iopub.execute_input":"2025-10-23T20:07:19.897158Z","iopub.status.idle":"2025-10-23T20:07:19.906796Z","shell.execute_reply.started":"2025-10-23T20:07:19.897139Z","shell.execute_reply":"2025-10-23T20:07:19.905838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_all","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:07:19.908344Z","iopub.execute_input":"2025-10-23T20:07:19.909042Z","iopub.status.idle":"2025-10-23T20:07:19.925456Z","shell.execute_reply.started":"2025-10-23T20:07:19.909010Z","shell.execute_reply":"2025-10-23T20:07:19.924579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_names = numeric_cols + list(ohe_feature_names)\nX_df = pd.DataFrame(X_all, columns=feature_names)\n\nX_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:07:19.926385Z","iopub.execute_input":"2025-10-23T20:07:19.926674Z","iopub.status.idle":"2025-10-23T20:07:19.960855Z","shell.execute_reply.started":"2025-10-23T20:07:19.926646Z","shell.execute_reply":"2025-10-23T20:07:19.959617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_ohe = OneHotEncoder(drop='first', sparse_output=False)  # drop='first to avoid dummy variable trap\n# y_ohe.fit(df_merged_new['country_group'].values.reshape(-1, 1))\n# y = y_ohe.transform(df_merged_new['country_group'].values.reshape(-1, 1))\n# y\n\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:19.965505Z","iopub.execute_input":"2025-10-23T20:07:19.965761Z","iopub.status.idle":"2025-10-23T20:07:19.980487Z","shell.execute_reply.started":"2025-10-23T20:07:19.965742Z","shell.execute_reply":"2025-10-23T20:07:19.979580Z"},"papermill":{"duration":0.025236,"end_time":"2025-10-15T21:18:24.570882","exception":false,"start_time":"2025-10-15T21:18:24.545646","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This block trains three neural-network classifiers to predict the hotel’s region class.**","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_all, y_encoded,\ntest_size=0.2, random_state=42,stratify=y_encoded)\n\n\n\n\n\ny_train = y_train.astype(np.int32).flatten()\ny_test = y_test.astype(np.int32).flatten()\n\nprint(y_train)\nprint(X_train)\nprint(y_test)\nprint(X_test)\n\n\n#model for training with class weights\nmodel = Sequential([\nInput(shape=(X_train.shape[1],)),\nlayers.Dense(32, activation='relu'),\nlayers.Dense(16, activation='relu'),\nlayers.Dense(8, activation='relu'),\nlayers.Dense(11, activation='softmax') # multi-class classification\n])\n\nmodel.compile(optimizer='adam',\nloss='sparse_categorical_crossentropy',\n metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')])\n\nmodel.summary()\n\n#model for training without class weights\nmodel1 = Sequential([\nInput(shape=(X_train.shape[1],)),\nlayers.Dense(32, activation='relu'),\nlayers.Dense(16, activation='relu'),\nlayers.Dense(8, activation='relu'),\nlayers.Dense(11, activation='softmax') # multi-class classification\n])\n\nmodel1.compile(optimizer='adam',\nloss='sparse_categorical_crossentropy',\n metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')])\n\nmodel1.summary()\n\n# --- Step 4: Create model2 (same architecture) ---\nmodel2 = Sequential([\n    Input(shape=(X_train2.shape[1],)),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(16, activation='relu'),\n    layers.Dense(8, activation='relu'),\n    layers.Dense(11, activation='softmax')  # multi-class classification\n])\n\nmodel2.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n)\n\nmodel2.summary()\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:19.981613Z","iopub.execute_input":"2025-10-23T20:07:19.981935Z","iopub.status.idle":"2025-10-23T20:07:20.254962Z","shell.execute_reply.started":"2025-10-23T20:07:19.981886Z","shell.execute_reply":"2025-10-23T20:07:20.254075Z"},"papermill":{"duration":0.170574,"end_time":"2025-10-15T21:18:24.855914","exception":false,"start_time":"2025-10-15T21:18:24.685340","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Training and Analysis","metadata":{}},{"cell_type":"markdown","source":"**This step trains all three models and compares the effect of class balancing and feature engineering.**","metadata":{}},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\ntf.keras.backend.clear_session()\n\n\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(y_encoded),\n    y=y_encoded\n)\n\nclass_weights_dict = dict(enumerate(class_weights))\n\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15,class_weight=class_weights_dict, batch_size=32)\n\nhistory1 = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=32)\n\nhistory2 = model2.fit(X_train2, y_train2,validation_data=(X_test2, y_test2),epochs=15,batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:07:20.255981Z","iopub.execute_input":"2025-10-23T20:07:20.256514Z","iopub.status.idle":"2025-10-23T20:09:22.508617Z","shell.execute_reply.started":"2025-10-23T20:07:20.256486Z","shell.execute_reply":"2025-10-23T20:09:22.507877Z"},"papermill":{"duration":53.786018,"end_time":"2025-10-15T21:19:18.659942","exception":false,"start_time":"2025-10-15T21:18:24.873924","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This plot compares how the training accuracy evolves over time (epochs) for all three models.**","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Accuracy (model with class weights)')\nplt.plot(history1.history['accuracy'], label='Train Accuracy (model without class weights)')\nplt.plot(history2.history['accuracy'], label='Train Accuracy (model with base comfort)')\nplt.xlabel('Epoch')\nplt.ylabel('Score')\nplt.title('Training Progress (Accuracy)')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:09:22.509997Z","iopub.execute_input":"2025-10-23T20:09:22.510218Z","iopub.status.idle":"2025-10-23T20:09:22.725920Z","shell.execute_reply.started":"2025-10-23T20:09:22.510202Z","shell.execute_reply":"2025-10-23T20:09:22.724948Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This block evaluates the model trained with class weights on the test dataset using multiple performance metrics.**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n\n# --- After model.fit() ---\ny_pred_probs = model.predict(X_test)           # predicted probabilities\ny_pred = np.argmax(y_pred_probs, axis=1)       # predicted class indices\ny_true = y_test                                # true labels\n\n# --- Compute metrics ---\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='macro')  # macro = treat all classes equally\nrecall = recall_score(y_true, y_pred, average='macro')\nf1 = f1_score(y_true, y_pred, average='macro')\n\nprint(f\"Accuracy:  {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall:    {recall:.4f}\")\nprint(f\"F1 Score:  {f1:.4f}\")\n\n# --- Optional: per-class breakdown ---\nprint(\"\\n Model with class weights Detailed classification report:\")\nprint(classification_report(y_true, y_pred, target_names=le.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:09:22.726879Z","iopub.execute_input":"2025-10-23T20:09:22.727147Z","iopub.status.idle":"2025-10-23T20:09:23.414697Z","shell.execute_reply.started":"2025-10-23T20:09:22.727128Z","shell.execute_reply":"2025-10-23T20:09:23.413689Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This block evaluates the baseline model (without class weights) on the same test dataset, to compare it against the weighted version.**","metadata":{}},{"cell_type":"code","source":"# --- After model.fit() ---\ny_pred_probs1 = model1.predict(X_test)           # predicted probabilities\ny_pred1 = np.argmax(y_pred_probs1, axis=1)       # predicted class indices\n\n# --- Compute metrics ---\naccuracy1 = accuracy_score(y_true, y_pred1)\nprecision1 = precision_score(y_true, y_pred1, average='macro')  # macro = treat all classes equally\nrecall1 = recall_score(y_true, y_pred1, average='macro')\nf1_1 = f1_score(y_true, y_pred1, average='macro')\n\nprint(f\"Accuracy:  {accuracy1:.4f}\")\nprint(f\"Precision: {precision1:.4f}\")\nprint(f\"Recall:    {recall1:.4f}\")\nprint(f\"F1 Score:  {f1_1:.4f}\")\n\n# --- Optional: per-class breakdown ---\nprint(\"\\n Model without class weights Detailed classification report:\")\nprint(classification_report(y_true, y_pred1, target_names=le.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:09:23.415818Z","iopub.execute_input":"2025-10-23T20:09:23.416602Z","iopub.status.idle":"2025-10-23T20:09:24.072883Z","shell.execute_reply.started":"2025-10-23T20:09:23.416571Z","shell.execute_reply":"2025-10-23T20:09:24.071949Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This block evaluates the third model (model2), which includes the engineered feature comfort_base, on its dedicated test set.**","metadata":{}},{"cell_type":"code","source":"# --- After model2.fit() ---\ny_pred_probs2 = model2.predict(X_test2)           # predicted probabilities\ny_pred2 = np.argmax(y_pred_probs2, axis=1)        # predicted class indices\n\n# --- Compute metrics ---\naccuracy2 = accuracy_score(y_test2, y_pred2)\nprecision2 = precision_score(y_test2, y_pred2, average='macro')  # macro = treat all classes equally\nrecall2 = recall_score(y_test2, y_pred2, average='macro')\nf1_2 = f1_score(y_test2, y_pred2, average='macro')\n\nprint(f\"Accuracy:  {accuracy2:.4f}\")\nprint(f\"Precision: {precision2:.4f}\")\nprint(f\"Recall:    {recall2:.4f}\")\nprint(f\"F1 Score:  {f1_2:.4f}\")\n\n# --- Optional: per-class breakdown ---\nprint(\"\\nModel with comfort_base Detailed classification report:\")\nprint(classification_report(y_test2, y_pred2, target_names=le.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:09:24.073846Z","iopub.execute_input":"2025-10-23T20:09:24.074555Z","iopub.status.idle":"2025-10-23T20:09:24.735328Z","shell.execute_reply.started":"2025-10-23T20:09:24.074532Z","shell.execute_reply":"2025-10-23T20:09:24.734407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import pairwise_distances_argmin_min\nidx, dist = pairwise_distances_argmin_min(X_test, X_train)\nprint(\"Minimum distance between test and train samples:\", dist.min())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:09:24.736651Z","iopub.execute_input":"2025-10-23T20:09:24.737185Z","iopub.status.idle":"2025-10-23T20:09:26.059580Z","shell.execute_reply.started":"2025-10-23T20:09:24.737163Z","shell.execute_reply":"2025-10-23T20:09:26.058632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predicted_class = np.argmax(y_pred, axis=1)\n# predicted_class[:100]","metadata":{"execution":{"iopub.status.busy":"2025-10-23T20:09:26.060559Z","iopub.execute_input":"2025-10-23T20:09:26.060872Z","iopub.status.idle":"2025-10-23T20:09:26.064954Z","shell.execute_reply.started":"2025-10-23T20:09:26.060847Z","shell.execute_reply":"2025-10-23T20:09:26.063987Z"},"papermill":{"duration":0.071228,"end_time":"2025-10-15T21:19:21.970666","exception":false,"start_time":"2025-10-15T21:19:21.899438","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This block explains the weighted model’s predictions using SHAP to show which features push the model toward or away from a specific class (here: Western_Europe).**","metadata":{}},{"cell_type":"code","source":"# Wrap your model prediction function\ndef predict_proba_fn(X):\n    preds = model.predict(X)\n    return preds\n# Use Explainer -> finds the best XAI model to use for your model\n# Use a small background (reference) set to speed up explanations\n# If X_train_scaled is a DataFrame, shap.sample will preserve columns\nbackground = shap.sample(X_train, 100, random_state=42)\n# Let SHAP pick the best algorithm for your Keras model\nexplainer = shap.Explainer(model, background)\nshap_values = explainer(X_test)\n\n# Combine numerical + one-hot encoded categorical names\nohe_feature_names = ohe_model.get_feature_names_out(categorical_cols)\nfeature_names = numeric_cols + list(ohe_feature_names)\n\n# --- Choose a class index to visualize ---\n# For example, visualize SHAP values for \"Western_Europe\"\nclass_index = np.where(le.classes_ == \"Western_Europe\")[0][0]\n\n# Get SHAP values for that class\nshap_values_class = shap_values[:, :, class_index]\n\n# --- Global SHAP Summary Plot ---\nshap.summary_plot(\n    shap_values_class.values,\n    X_test,\n    feature_names=feature_names,\n    show=True\n)\n\n# --- Local SHAP Force Plot for one test instance ---\ni = 0  # index of instance to explain\nshap.initjs()\nshap.plots.force(shap_values[i, :, class_index], feature_names=feature_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:09:26.065966Z","iopub.execute_input":"2025-10-23T20:09:26.066304Z","iopub.status.idle":"2025-10-23T20:27:32.556414Z","shell.execute_reply.started":"2025-10-23T20:09:26.066274Z","shell.execute_reply":"2025-10-23T20:27:32.555401Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Since computing SHAP values for the entire test set can be computationally expensive, we take a random sample of 500 test instances to generate interpretable visualizations more efficiently.**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# --- Sample 500 random instances from X_test ---\nsample_size = 500\nsample_idx = np.random.choice(len(X_test), sample_size, replace=False)\n\nX_test_sample = X_test.iloc[sample_idx] if isinstance(X_test, pd.DataFrame) else X_test[sample_idx]\n\n# --- Compute SHAP values on the sample only ---\nshap_values_sample = explainer(X_test_sample)\n\n# --- Choose the target class ---\nclass_index = np.where(le.classes_ == \"Western_Europe\")[0][0]\n\n# Extract SHAP values for that class\nshap_values_class = shap_values_sample[:, :, class_index]\n\n# --- Global SHAP Summary Plot ---\nshap.summary_plot(\n    shap_values_class.values,\n    X_test_sample,\n    feature_names=feature_names,\n    show=True\n)\n\n# --- Local Force Plot (for one random instance among the sample) ---\ni = 0\nshap.initjs()\nshap.plots.force(shap_values_sample[i, :, class_index], feature_names=feature_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:27:32.557703Z","iopub.execute_input":"2025-10-23T20:27:32.558033Z","iopub.status.idle":"2025-10-23T20:28:26.309126Z","shell.execute_reply.started":"2025-10-23T20:27:32.558009Z","shell.execute_reply":"2025-10-23T20:28:26.308107Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This section uses LIME to explain how individual feature values influence one specific prediction made by the model.**","metadata":{}},{"cell_type":"code","source":"# --- Step 1: Define your predict function ---\n# LIME expects a function that returns probabilities for each class\npredict_fn = lambda x: model.predict(x).astype(float)\n\n# --- Step 2: Create the LIME explainer ---\nexplainer_lime = lime.lime_tabular.LimeTabularExplainer(\n    X_train,                            # numpy array or DataFrame values\n    feature_names=feature_names,        # all feature names\n    class_names=le.classes_,            # your encoded country_group classes\n    discretize_continuous=True,         # discretize continuous vars for interpretability\n    mode='classification'               # since this is a multi-class classification task\n)\n\n# --- Step 3: Pick one test instance to explain ---\ni = 60   # for example, index 60\nexp = explainer_lime.explain_instance(\n    X_test[70],                          # the test sample\n    predict_fn,                         # your model’s predict function\n    num_features=10,                    # number of top features to show\n    top_labels=1                        # only explain the top predicted label\n)\n\n# --- Step 4: Display explanation ---\nexp.show_in_notebook(show_table=True, show_all=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:28:26.310147Z","iopub.execute_input":"2025-10-23T20:28:26.310407Z","iopub.status.idle":"2025-10-23T20:28:26.976869Z","shell.execute_reply.started":"2025-10-23T20:28:26.310381Z","shell.execute_reply":"2025-10-23T20:28:26.975917Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This helper takes one user/hotel-review profile, applies the same preprocessing used during training, and returns:\nthe predicted region (country_group) the full class–probability distribution.**","metadata":{}},{"cell_type":"code","source":"def predict_country_group(\n    user_gender,\n    age_group,\n    traveller_type,\n    score_overall,\n    score_cleanliness,\n    score_comfort,\n    score_facilities,\n    score_location,\n    score_staff,\n    score_value_for_money,\n    model,\n    ohe_model,\n    scaler,\n    le\n):\n    # --- Step 1: Define column order ---\n    categorical_cols = ['user_gender', 'age_group', 'traveller_type']\n    numeric_cols = [\n        'score_overall', 'score_cleanliness', 'score_comfort',\n        'score_facilities', 'score_location', 'score_staff', 'score_value_for_money'\n    ]\n\n    # --- Step 2: Create single-row DataFrame ---\n    data = pd.DataFrame([{\n        'user_gender': user_gender,\n        'age_group': age_group,\n        'traveller_type': traveller_type,\n        'score_overall': score_overall,\n        'score_cleanliness': score_cleanliness,\n        'score_comfort': score_comfort,\n        'score_facilities': score_facilities,\n        'score_location': score_location,\n        'score_staff': score_staff,\n        'score_value_for_money': score_value_for_money\n    }])\n\n    # --- Step 3: Preprocess categorical and numeric features ---\n    X_cat = ohe_model.transform(data[categorical_cols])\n    X_num = scaler.transform(data[numeric_cols])\n\n    # --- Step 4: Combine features ---\n    X_input = np.hstack([X_num, X_cat])\n\n    # --- Step 5: Predict probabilities ---\n    y_proba = model.predict(X_input)\n    y_pred = np.argmax(y_proba, axis=1)\n\n    # --- Step 6: Decode label back to country_group ---\n    predicted_group = le.inverse_transform(y_pred)[0]\n\n    # --- Step 7: Return both prediction and probabilities ---\n    return {\n        \"predicted_country_group\": predicted_group,\n        \"probabilities\": dict(zip(le.classes_, y_proba[0]))\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:28:26.977959Z","iopub.execute_input":"2025-10-23T20:28:26.978216Z","iopub.status.idle":"2025-10-23T20:28:26.985724Z","shell.execute_reply.started":"2025-10-23T20:28:26.978189Z","shell.execute_reply":"2025-10-23T20:28:26.984827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This step demonstrates how to use the trained model and preprocessing pipeline to predict the most likely country group for a single user review profile.**","metadata":{}},{"cell_type":"code","source":"result = predict_country_group(\n    user_gender='Female',\n    age_group='25-34',\n    traveller_type='Solo',\n    score_overall=8.7,\n    score_cleanliness=8.6,\n    score_comfort=8.7,\n    score_facilities=8.5,\n    score_location=9.0,\n    score_staff=8.8,\n    score_value_for_money=8.7,\n    model=model,      # your trained classifier\n    ohe_model=ohe_model, # your fitted OneHotEncoder\n    scaler=scaler,       # your fitted StandardScaler\n    le=le                # your fitted LabelEncoder for country_group\n)\n\nprint(\"Predicted Country Group:\", result[\"predicted_country_group\"])\nprint(\"Class Probabilities:\", result[\"probabilities\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:28:26.986695Z","iopub.execute_input":"2025-10-23T20:28:26.986955Z","iopub.status.idle":"2025-10-23T20:28:27.120285Z","shell.execute_reply.started":"2025-10-23T20:28:26.986930Z","shell.execute_reply":"2025-10-23T20:28:27.119447Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**This cell allows you to manually input traveler details and receive a predicted country group with its probability distribution.**","metadata":{}},{"cell_type":"code","source":"print(\"Please enter the following details:\\n\")\n\n    # --- Get categorical inputs ---\nuser_gender = input(\"User gender (Male/Female): \")\nage_group = input(\"Age group (e.g., 18-24, 25-34, 35-44, etc.): \")\ntraveller_type = input(\"Traveller type (e.g., Solo traveller, Couple, Family, Friends): \")\n\n# --- Get numeric inputs ---\ncomfort_base = float(input(\"Comfort base (e.g., 3.5): \"))\nscore_overall = float(input(\"Score overall: \"))\nscore_cleanliness = float(input(\"Score cleanliness: \"))\nscore_comfort = float(input(\"Score comfort: \"))\nscore_facilities = float(input(\"Score facilities: \"))\nscore_location = float(input(\"Score location: \"))\nscore_staff = float(input(\"Score staff: \"))\nscore_value_for_money = float(input(\"Score value for money: \"))\n\nresult = predict_country_group(\n    user_gender,\n    age_group,\n    traveller_type,\n    comfort_base,\n    score_overall,\n    score_cleanliness,\n    score_comfort,\n    score_facilities,\n    score_location,\n    score_staff,\n    score_value_for_money,\n    model=model,      # your trained classifier\n    ohe_model=ohe_model, # your fitted OneHotEncoder\n    scaler=scaler,       # your fitted StandardScaler\n    le=le                # your fitted LabelEncoder for country_group\n)\n\nprint(\"Predicted Country Group:\", result[\"predicted_country_group\"])\nprint(\"Class Probabilities:\", result[\"probabilities\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T20:28:27.121195Z","iopub.execute_input":"2025-10-23T20:28:27.121467Z","iopub.status.idle":"2025-10-23T21:09:52.435518Z","shell.execute_reply.started":"2025-10-23T20:28:27.121438Z","shell.execute_reply":"2025-10-23T21:09:52.434067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndf_merged[:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:09:52.436194Z","iopub.status.idle":"2025-10-23T21:09:52.436522Z","shell.execute_reply.started":"2025-10-23T21:09:52.436350Z","shell.execute_reply":"2025-10-23T21:09:52.436362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}